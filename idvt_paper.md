
# Interaction Data Visualisation Tool (IDVT)


## Introduction

Interaction data is messy, there is a lot of it; complicated, it is challenging to read;
and difficult to work with due to the number of unique features.

However, interaction data has the potential to be a great resource in identifying audience
behaviour (ref Measuring Behaviours paper?, see other refs used to see if applicable).

I've created a web based data visualisation tool for the initial analysis of low level interaction data taken from user experiences. It provides a way to create abstractions and visualisations of the data to inform a feature selection process that can tease out audience behaviours.  

## What Does The Tool Do?

The IDVT takes the interaction data and creates a set of plots that visualise the type and density
of clicks, as well as summary statistics such as total number of clicks, average number of
clicks per second and total time taken.

The tool is designed to take a CSV file with comma separated values as an input. 
It then runs a Python script to pre process the data to clean up and infinite or NAN values as well as making sure it contains the columns needed to create the visualisations, and, if not, generating the columns. Another two scripts construct
the visualisations, one that reveals the type of button clicks on a timeline
([action_item.py](https://github.com/UoMResearchIT/bbc_data_flask_app/blob/master/static/scripts/action_item.py))
and another that plots the density of button clicks in each five minute interval of the experience
([click_density.py](https://github.com/UoMResearchIT/bbc_data_flask_app/blob/master/static/scripts/click_density.py)).








### Essential Columns

* **participant_id** - that refers to the individual users of the interactive experience.
* **timestamp** - point in time when the event occurred, in datetime format eg (2017-08-17 19:41:09)
* **item** - button participant has clicked on e.g. play button
* **action** - the result of clicking button e.g. play, pause etc.

All other columns needed will be generated by either `data_pre_pro.py` or `create_stats.py`

### Run Analysis

Clicking Run Analysis will take the CSV file uploaded by the user and create visualisations using the open source
[Plotly for Python](https://github.com/plotly/plotly.py)

It will run the following scripts -

* `data_pre_pro.py` - pre processes the data to get rid of inf, and NAN values.
Will also create the 'time_diff' and 'action_item' columns needed for the plots.

* `action_item.py` - takes the processed data and plots the type of clicks (i.e action_item) across time.

* `click_density.py` - plots the density of clicks across a 300 second (5 minute intervals)

* `create_stats.py`- creates a CSV of the statistical data such as click count,time taken in minutes/seconds, clicks per minute/second, minutes/secs per click.
this is then used to create histograms.

* `histogram_click_count.py`, `histogram_clicks_per_min.py` and `histogram_time_taken.py` create histograms based on the click count, clicks per minute and time taken.

Each data file uploaded by the user will create its own directory in `static/output` to store the relevant outputs.

All plots and an HTML version of the stats are also saved in `templates/` to be rendered by the `vis.html` template.

## What Can Be Gained from this Tool?

Insight into which features are important,

clicks - colour coding
density - see when most of the clicks are happening

histograms - can see patterns of time, clicks, clicks per minute. Why are these important?

## Applications?

Speed up initial analysis and features to look out for.


## Limitations

Large Data Sets = takes longer to get the data needed for plots, lots of statistical noise.
